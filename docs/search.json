[
  {
    "objectID": "Removed_Code.html",
    "href": "Removed_Code.html",
    "title": "Adaptive Capacity of New York City",
    "section": "",
    "text": "#| fig-cap: \"FEMA Flooding area in New York City\"\n\n    import pygris\n    NYC_county_code = [\"005\",\"047\",\"061\",\"081\",\"085\"]\n    NY_state_code = \"36\"\n    NYC_block_groups = pygris.block_groups(\n    state=NY_state_code, county=NYC_county_code, year=2022\n)\n    import geopandas as gpd\n    import pandas as pd\n    from matplotlib import pyplot as plt\n    FEMA = gpd.read_file('./analysis/Shapefiles/FEMA.shp')\n    fig, ax = plt.subplots(figsize=(10, 10))\n    NYC_block_groups.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=0.3)\n    FEMA.plot(ax=ax, facecolor=\"blue\", edgecolor=\"black\", linewidth=0.5)\n    \n\n\n\n    MS4 = gpd.read_file('./Shapefiles/MS4_Area.shp')\n    fig, ax = plt.subplots(figsize=(10, 10))\n    NYC_block_groups.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=0.3)\n    MS4.to_crs(epsg=4326).plot(ax=ax, facecolor=\"gray\", edgecolor=\"black\", linewidth=0.5)"
  },
  {
    "objectID": "Analysis_Main.html",
    "href": "Analysis_Main.html",
    "title": "Adaptive Capacity of New York City",
    "section": "",
    "text": "import pygris\n\n\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\n\nimport requests\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport holoviews as hv\nimport hvplot.pandas\n\nimport cenpy\n\npd.options.display.max_columns = 999\npd.options.display.max_colwidth = None\n\navailable = cenpy.explorer.available()\n\nacs = available.filter(regex=\"^ACS\", axis=0)\n\navailable.filter(regex=\"^ACSDT5Y\", axis=0)\n\ncenpy.explorer.explain(\"ACSDT5Y2022\")\n\n\n\n\n\n\n\n\n\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_dist(x, y):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:165: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def get_faces(triangle):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:199: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:261: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_mask_faces(mask, faces):\n\n\n{'American Community Survey: 5-Year Estimates: Detailed Tables 5-Year': 'The American Community Survey (ACS) is an ongoing survey that provides data every year -- giving communities the current information they need to plan investments and services. The ACS covers a broad range of topics about social, economic, demographic, and housing characteristics of the U.S. population. Summary files include the following geographies: nation, all states (including DC and Puerto Rico), all metropolitan areas, all congressional districts, all counties, all places, and all tracts and block groups. Summary files contain the most detailed cross-tabulations, many of which are published down to block groups. The data are population and housing counts. There are over 64,000 variables in this dataset.'}\n\n\n\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2022\")\n\nlen(acs.variables)\n\n28193\n\n\n\nhousing_cost = acs.varslike(\n    pattern=\"MEDIAN MONTHLY HOUSING COSTS\",\n    by=\"concept\",  # searches along concept column\n).sort_index()\nhousing_cost.head(1)\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\n\n\n\n\n\n\nelderly = acs.varslike(\n    pattern=\"Households with one or more people 60 years and over\",\n    by=\"label\",  # searches along concept column\n).sort_index()\nelderly.head(1)\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\nB11006_002E\nEstimate!!Total:!!Households with one or more people 60 years and over:\nHouseholds by Presence of People 60 Years and Over by Household Type\nint\nB11006\n0\nNaN\nNaN\nB11006_002EA,B11006_002M,B11006_002MA\nNaN\n\n\n\n\n\n\n\n\nvacancy = acs.varslike(\n    pattern=\"B25003\",\n    by=\"group\",  # searches along concept column\n).sort_index()\nvacancy.head(3)\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\nB25003A_001E\nEstimate!!Total:\nTenure (White Alone Householder)\nint\nB25003A\n0\nNaN\nNaN\nB25003A_001EA,B25003A_001M,B25003A_001MA\nNaN\n\n\nB25003A_002E\nEstimate!!Total:!!Owner occupied\nTenure (White Alone Householder)\nint\nB25003A\n0\nNaN\nNaN\nB25003A_002EA,B25003A_002M,B25003A_002MA\nNaN\n\n\nB25003A_003E\nEstimate!!Total:!!Renter occupied\nTenure (White Alone Householder)\nint\nB25003A\n0\nNaN\nNaN\nB25003A_003EA,B25003A_003M,B25003A_003MA\nNaN\n\n\n\n\n\n\n\n\nownership = acs.varslike(\n    pattern=\"owner\",\n    by=\"label\",  # searches along concept column\n).sort_index()\nownership.head()\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\nB07013PR_002E\nEstimate!!Total:!!Householder lived in owner-occupied housing units\nGeographical Mobility in the Past Year by Tenure for Current Residence in Puerto Rico\nint\nB07013PR\n0\nNaN\nNaN\nB07013PR_002EA,B07013PR_002M,B07013PR_002MA\nNaN\n\n\nB07013PR_005E\nEstimate!!Total:!!Same house 1 year ago:!!Householder lived in owner-occupied housing units\nGeographical Mobility in the Past Year by Tenure for Current Residence in Puerto Rico\nint\nB07013PR\n0\nNaN\nNaN\nB07013PR_005EA,B07013PR_005M,B07013PR_005MA\nNaN\n\n\nB07013PR_008E\nEstimate!!Total:!!Moved within same municipio:!!Householder lived in owner-occupied housing units\nGeographical Mobility in the Past Year by Tenure for Current Residence in Puerto Rico\nint\nB07013PR\n0\nNaN\nNaN\nB07013PR_008EA,B07013PR_008M,B07013PR_008MA\nNaN\n\n\nB07013PR_011E\nEstimate!!Total:!!Moved from different municipio:!!Householder lived in owner-occupied housing units\nGeographical Mobility in the Past Year by Tenure for Current Residence in Puerto Rico\nint\nB07013PR\n0\nNaN\nNaN\nB07013PR_011EA,B07013PR_011M,B07013PR_011MA\nNaN\n\n\nB07013PR_014E\nEstimate!!Total:!!Moved from the United States:!!Householder lived in owner-occupied housing units\nGeographical Mobility in the Past Year by Tenure for Current Residence in Puerto Rico\nint\nB07013PR\n0\nNaN\nNaN\nB07013PR_014EA,B07013PR_014M,B07013PR_014MA\nNaN\n\n\n\n\n\n\n\n\npopulation = acs.varslike(\n    pattern=\"Population\",\n    by=\"concept\",  # searches along concept column\n).sort_index()\npopulation.head(1)\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\nB01003_001E\nEstimate!!Total\nTotal Population\nint\nB01003\n0\nNaN\nNaN\nB01003_001EA,B01003_001M,B01003_001MA\nNaN\n\n\n\n\n\n\n\n\npoverty = acs.varslike(\n    pattern=\"Percent!!YEAR STRUCTURE BUILT!!Total housing units!!Built 1939 or earlier\",\n    by=\"label\",  # searches along concept column\n).sort_index()\npoverty.head(2)\n\n\n\n\n\n\n\n\nlabel\nconcept\npredicateType\ngroup\nlimit\npredicateOnly\nhasGeoCollectionSupport\nattributes\nrequired\n\n\n\n\n\n\n\n\n\n\nvariables = [\n    \"NAME\",\n    \"B11006_002E\", #Households with one or more people 60 years and over\n    \"B25002_003E\", #Vacancy\n    \"B25003_003E\", #Renter Occupation\n    \"B01003_001E\", #Total Population\n    \"B19013_001E\", #Median household income\n    \"B25035_001E\", #Median year built\n]\n\n\nNYC_county_code = [\"005\",\"047\",\"061\",\"081\",\"085\"]\nNY_state_code = \"36\"\n\ncounty_codes = \",\".join(NYC_county_code)\n\nNYC_demo_data = acs.query(\n    cols=variables,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": NY_state_code, \"county\": county_codes, \"tract\": \"*\"},\n)\n\nNYC_demo_data.head()\n\n\n\n\n\n\n\n\nNAME\nB11006_002E\nB25002_003E\nB25003_003E\nB01003_001E\nB19013_001E\nB25035_001E\nstate\ncounty\ntract\nblock group\n\n\n\n\n0\nBlock Group 0; Census Tract 1; Bronx County; New York\n0\n0\n0\n0\n-666666666\n-666666666\n36\n005\n000100\n0\n\n\n1\nBlock Group 1; Census Tract 1; Bronx County; New York\n0\n0\n0\n4446\n-666666666\n-666666666\n36\n005\n000100\n1\n\n\n2\nBlock Group 0; Census Tract 2; Bronx County; New York\n0\n0\n0\n0\n-666666666\n-666666666\n36\n005\n000200\n0\n\n\n3\nBlock Group 1; Census Tract 2; Bronx County; New York\n230\n15\n99\n1210\n123208\n1953\n36\n005\n000200\n1\n\n\n4\nBlock Group 2; Census Tract 2; Bronx County; New York\n302\n31\n379\n2111\n115764\n1964\n36\n005\n000200\n2\n\n\n\n\n\n\n\n\nNYC_block_groups = pygris.block_groups(\n    state=NY_state_code, county=NYC_county_code, year=2022\n)\n\n\nNYC_demo_final = NYC_block_groups.merge(\n    NYC_demo_data,\n    left_on=[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"BLKGRPCE\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\nNYC_demo_final.head(1)\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nBLKGRPCE\nGEOID\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME\nB11006_002E\nB25002_003E\nB25003_003E\nB01003_001E\nB19013_001E\nB25035_001E\nstate\ncounty\ntract\nblock group\n\n\n\n\n0\n36\n047\n059403\n1\n360470594031\nBlock Group 1\nG5030\nS\n64626\n0\n+40.5964380\n-073.9474106\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n142\n53\n62\n1185\n125417\n1938\n36\n047\n059403\n1\n\n\n\n\n\n\n\n\nNYC_demo_final.rename(columns={\n    \"B11006_002E\": \"Households with 60+\",\n    \"B25002_003E\": \"Vacancy\",\n    \"B25003_003E\": \"Renter Occupation\",\n    \"B01003_001E\": \"Total Population\",\n    \"B19013_001E\": \"Median Household Income\",\n    \"B25035_001E\": \"Median Year Built\"\n}, inplace=True)\nNYC_demo_final['Households with 60+'] = pd.to_numeric(NYC_demo_final['Households with 60+'], errors='coerce').fillna(0).astype(float)\nNYC_demo_final['Vacancy'] = pd.to_numeric(NYC_demo_final['Vacancy'], errors='coerce').fillna(0).astype(float)\nNYC_demo_final['Renter Occupation'] = pd.to_numeric(NYC_demo_final['Renter Occupation'], errors='coerce').fillna(0).astype(float)\nNYC_demo_final['Total Population'] = pd.to_numeric(NYC_demo_final['Total Population'], errors='coerce').fillna(0).astype(float)\n\nNYC_demo_final['Median Household Income'] = pd.to_numeric(NYC_demo_final['Median Household Income'], errors='coerce').fillna(0).astype(float)\nmedian1 = NYC_demo_final['Median Household Income'].median()\nNYC_demo_final['Median Household Income'] = NYC_demo_final['Median Household Income'].mask(NYC_demo_final['Median Household Income'] &lt; 0, median1)\n\nNYC_demo_final['Median Year Built'] = pd.to_numeric(NYC_demo_final['Median Year Built'], errors='coerce').fillna(0).astype(float)\nmedian2 = NYC_demo_final['Median Year Built'].median()\nNYC_demo_final['Median Year Built'] = NYC_demo_final['Median Year Built'].mask(NYC_demo_final['Median Year Built'] &lt; 0, median2)\n\nNYC_demo_final.head(2)\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nBLKGRPCE\nGEOID\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME\nHouseholds with 60+\nVacancy\nRenter Occupation\nTotal Population\nMedian Household Income\nMedian Year Built\nstate\ncounty\ntract\nblock group\n\n\n\n\n0\n36\n047\n059403\n1\n360470594031\nBlock Group 1\nG5030\nS\n64626\n0\n+40.5964380\n-073.9474106\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n142.0\n53.0\n62.0\n1185.0\n125417.0\n1938.0\n36\n047\n059403\n1\n\n\n1\n36\n047\n059403\n2\n360470594032\nBlock Group 2\nG5030\nS\n76076\n0\n+40.5941323\n-073.9474463\nPOLYGON ((-73.94952 40.59499, -73.94859 40.59509, -73.94766 40.59519, -73.94674 40.59529, -73.94577 40.59540, -73.94537 40.59328, -73.94634 40.59317, -73.94726 40.59307, -73.94819 40.59297, -73.94912 40.59287, -73.94952 40.59499))\nBlock Group 2; Census Tract 594.03; Kings County; New York\n120.0\n77.0\n106.0\n800.0\n88214.0\n1938.0\n36\n047\n059403\n2\n\n\n\n\n\n\n\n\nNYC_demo_final_Normalized = NYC_demo_final\n\nNYC_demo_final_Normalized['Households with 60+'] = NYC_demo_final_Normalized['Households with 60+']/-1000\nNYC_demo_final_Normalized['Vacancy'] = NYC_demo_final_Normalized['Vacancy']/500\nNYC_demo_final_Normalized['Renter Occupation'] = NYC_demo_final_Normalized['Renter Occupation']/1500\nNYC_demo_final_Normalized['Total Population'] = NYC_demo_final_Normalized['Total Population']/-6000\nNYC_demo_final_Normalized['Median Household Income'] = NYC_demo_final_Normalized['Median Household Income']/-200000\nNYC_demo_final_Normalized['Median Year Built'] = (NYC_demo_final_Normalized['Median Year Built'] - 1900)/122\nNYC_demo_final_Normalized.head(1)\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nBLKGRPCE\nGEOID\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME\nHouseholds with 60+\nVacancy\nRenter Occupation\nTotal Population\nMedian Household Income\nMedian Year Built\nstate\ncounty\ntract\nblock group\n\n\n\n\n0\n36\n047\n059403\n1\n360470594031\nBlock Group 1\nG5030\nS\n64626\n0\n+40.5964380\n-073.9474106\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n-0.142\n0.106\n0.041333\n-0.1975\n-0.627085\n0.311475\n36\n047\n059403\n1\n\n\n\n\n\n\n\n\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.font_manager as font_manager\n\n\nNYC_demo_final_Normalized_Indexed = NYC_demo_final_Normalized\nNYC_demo_final_Normalized_Indexed.index = NYC_demo_final_Normalized_Indexed['GEOID']\ncolumns_to_keep = [\"Households with 60+\",\"Vacancy\",\"Renter Occupation\",\n                                   \"Total Population\",\"Median Household Income\",\"Median Year Built\"]\nnew_df = NYC_demo_final_Normalized_Indexed[columns_to_keep]\n\n\nk = -(1/np.log(new_df.shape[0]))\n\ndef entropy(X):\n    return (X*np.log(X)).sum()*k\n\nentropy = new_df.apply(entropy)\n\ndod = 1 - entropy\n\nw = dod/dod.sum()\nw.sort_values(ascending = False)\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n\n\nMedian Year Built          0.461299\nRenter Occupation          0.345718\nVacancy                    0.198211\nHouseholds with 60+       -0.001743\nTotal Population          -0.001743\nMedian Household Income   -0.001743\ndtype: float64\n\n\n\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized['Vacancy']*0.198211\nNYC_demo_final_Normalized.head()\n\n\n\n\n\n\n\n\nSTATEFP\nCOUNTYFP\nTRACTCE\nBLKGRPCE\nGEOID\nNAMELSAD\nMTFCC\nFUNCSTAT\nALAND\nAWATER\nINTPTLAT\nINTPTLON\ngeometry\nNAME\nHouseholds with 60+\nVacancy\nRenter Occupation\nTotal Population\nMedian Household Income\nMedian Year Built\nstate\ncounty\ntract\nblock group\nAdaptivity\n\n\nGEOID\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n360470594031\n36\n047\n059403\n1\n360470594031\nBlock Group 1\nG5030\nS\n64626\n0\n+40.5964380\n-073.9474106\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n-0.142\n0.106\n0.041333\n-0.197500\n-0.627085\n0.311475\n36\n047\n059403\n1\n0.021010\n\n\n360470594032\n36\n047\n059403\n2\n360470594032\nBlock Group 2\nG5030\nS\n76076\n0\n+40.5941323\n-073.9474463\nPOLYGON ((-73.94952 40.59499, -73.94859 40.59509, -73.94766 40.59519, -73.94674 40.59529, -73.94577 40.59540, -73.94537 40.59328, -73.94634 40.59317, -73.94726 40.59307, -73.94819 40.59297, -73.94912 40.59287, -73.94952 40.59499))\nBlock Group 2; Census Tract 594.03; Kings County; New York\n-0.120\n0.154\n0.070667\n-0.133333\n-0.441070\n0.311475\n36\n047\n059403\n2\n0.030524\n\n\n360470594042\n36\n047\n059404\n2\n360470594042\nBlock Group 2\nG5030\nS\n75413\n0\n+40.5908487\n-073.9477886\nPOLYGON ((-73.94912 40.59287, -73.94819 40.59297, -73.94726 40.59307, -73.94686 40.59095, -73.94646 40.58883, -73.94738 40.58873, -73.94831 40.58863, -73.94872 40.59075, -73.94912 40.59287))\nBlock Group 2; Census Tract 594.04; Kings County; New York\n-0.185\n0.098\n0.114667\n-0.290500\n-0.709745\n0.311475\n36\n047\n059404\n2\n0.019425\n\n\n360470594041\n36\n047\n059404\n1\n360470594041\nBlock Group 1\nG5030\nS\n96434\n0\n+40.5908731\n-073.9455877\nPOLYGON ((-73.94726 40.59307, -73.94634 40.59317, -73.94537 40.59328, -73.94497 40.59116, -73.94401 40.59126, -73.94361 40.58915, -73.94457 40.58904, -73.94553 40.58893, -73.94646 40.58883, -73.94686 40.59095, -73.94726 40.59307))\nBlock Group 1; Census Tract 594.04; Kings County; New York\n-0.261\n0.000\n0.108000\n-0.220833\n-0.245645\n0.311475\n36\n047\n059404\n1\n0.000000\n\n\n360470594043\n36\n047\n059404\n3\n360470594043\nBlock Group 3\nG5030\nS\n42052\n0\n+40.5906922\n-073.9492328\nPOLYGON ((-73.95015 40.59275, -73.94912 40.59287, -73.94872 40.59075, -73.94831 40.58863, -73.94934 40.58851, -73.94975 40.59063, -73.95015 40.59275))\nBlock Group 3; Census Tract 594.04; Kings County; New York\n-0.317\n0.000\n0.441333\n-0.236500\n-0.248855\n0.377049\n36\n047\n059404\n3\n0.000000\n\n\n\n\n\n\n\n\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.461299*NYC_demo_final_Normalized['Median Year Built']\n\n\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.345718*NYC_demo_final_Normalized['Renter Occupation']\n\n\ncolumns_to_keep_2 = [\"GEOID\",\"Adaptivity\",\"geometry\",\"NAME\"]\nNYC_Adaptive_Capacity = NYC_demo_final_Normalized[columns_to_keep_2]\nNYC_Adaptive_Capacity.reset_index(inplace=True, drop=True)\nNYC_Adaptive_Capacity.head()\n\n\n\n\n\n\n\n\nGEOID\nAdaptivity\ngeometry\nNAME\n\n\n\n\n0\n360470594031\n0.178983\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n\n\n1\n360470594032\n0.198639\nPOLYGON ((-73.94952 40.59499, -73.94859 40.59509, -73.94766 40.59519, -73.94674 40.59529, -73.94577 40.59540, -73.94537 40.59328, -73.94634 40.59317, -73.94726 40.59307, -73.94819 40.59297, -73.94912 40.59287, -73.94952 40.59499))\nBlock Group 2; Census Tract 594.03; Kings County; New York\n\n\n2\n360470594042\n0.202750\nPOLYGON ((-73.94912 40.59287, -73.94819 40.59297, -73.94726 40.59307, -73.94686 40.59095, -73.94646 40.58883, -73.94738 40.58873, -73.94831 40.58863, -73.94872 40.59075, -73.94912 40.59287))\nBlock Group 2; Census Tract 594.04; Kings County; New York\n\n\n3\n360470594041\n0.181021\nPOLYGON ((-73.94726 40.59307, -73.94634 40.59317, -73.94537 40.59328, -73.94497 40.59116, -73.94401 40.59126, -73.94361 40.58915, -73.94457 40.58904, -73.94553 40.58893, -73.94646 40.58883, -73.94686 40.59095, -73.94726 40.59307))\nBlock Group 1; Census Tract 594.04; Kings County; New York\n\n\n4\n360470594043\n0.326509\nPOLYGON ((-73.95015 40.59275, -73.94912 40.59287, -73.94872 40.59075, -73.94831 40.58863, -73.94934 40.58851, -73.94975 40.59063, -73.95015 40.59275))\nBlock Group 3; Census Tract 594.04; Kings County; New York\n\n\n\n\n\n\n\n\nCriteria1_2 = pd.read_csv('./analysis/Data/Adaptive_And_Development.csv')\nNYC_Adaptive_Capacity['GEOID'] = NYC_Adaptive_Capacity['GEOID'].astype(str)\nNYC_Adaptive_Capacity['GEOID'] = NYC_Adaptive_Capacity['GEOID'].apply(lambda x: x[:-1])\nCriteria1_2['GEOID'] = Criteria1_2['GEOID'].astype(str)\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\nCriteria1_2.head()\n\n\n\n\n\n\n\n\nOID_\nGEOID\nALAND\nAWATER\nNAME\nState\nCounty\nB01001_001E\nB25002_001E\nB25002_002E\nB25002_003E\nHOUSING_DENSITY\nADAPTIVE\nDEVELOPMENT\n\n\n\n\n0\n1\n36085000300\n377461.0\n2080565.0\nCensus Tract 3\nNew York\nRichmond County\n2187\n1224\n1087\n137\n3.242719\n5.454462\n18.831325\n\n\n1\n2\n36085000600\n666769.0\n2045497.0\nCensus Tract 6\nNew York\nRichmond County\n2484\n1439\n1309\n130\n2.158169\n10.511640\n33.906883\n\n\n2\n3\n36085000700\n528114.0\n605460.0\nCensus Tract 7\nNew York\nRichmond County\n4578\n2203\n1940\n263\n4.171448\n3.337458\n26.703180\n\n\n3\n4\n36085000800\n799850.0\n0.0\nCensus Tract 8\nNew York\nRichmond County\n5751\n2196\n1926\n270\n2.745515\n12.783682\n30.304741\n\n\n4\n5\n36085000900\n231877.0\n0.0\nCensus Tract 9\nNew York\nRichmond County\n1924\n1006\n740\n266\n4.338507\n2.344675\n30.374046\n\n\n\n\n\n\n\n\nAdaptive_Capacity = NYC_Adaptive_Capacity.merge(Criteria1_2, on='GEOID')\nmax_value_1 = Adaptive_Capacity['ADAPTIVE'].max()\nmax_value_2 = Adaptive_Capacity['DEVELOPMENT'].max()\nAdaptive_Capacity['ADAPTIVE'] = Adaptive_Capacity['ADAPTIVE']/ max_value_1\nAdaptive_Capacity['DEVELOPMENT'] = Adaptive_Capacity['DEVELOPMENT']/ max_value_2\n\n\ncolumns_to_keep_3 = ['ADAPTIVE','DEVELOPMENT',\"Adaptivity\"]\nFinal_TOPSIS = Adaptive_Capacity[columns_to_keep_3]\n\n\nk = -(1/np.log(Final_TOPSIS.shape[0]))\n\ndef entropy(X):\n    return (X*np.log(X)).sum()*k\n\nentropy = Final_TOPSIS.apply(entropy)\n\ndod = 1 - entropy\n\nw = dod/dod.sum()\nw.sort_values(ascending = False)\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n\n\nAdaptivity     0.352945\nADAPTIVE       0.329026\nDEVELOPMENT    0.318029\ndtype: float64\n\n\n\ncolumns_to_keep_4 = [\"GEOID\",'ADAPTIVE','DEVELOPMENT',\"Adaptivity\",\"geometry\",\"NAME_x\"]\nConclusion = Adaptive_Capacity[columns_to_keep_4]\nConclusion[\"TOPSIS_CALIBRATED\"]=Conclusion[\"Adaptivity\"]*0.352945 + Conclusion[\n    \"ADAPTIVE\"]*0.329026 + Conclusion[\"DEVELOPMENT\"]*0.318029\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\nConclusion.fillna(0, inplace=True)\n\nC:\\Users\\Josh Williamson\\AppData\\Local\\Temp\\ipykernel_15076\\4250588969.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  Conclusion.fillna(0, inplace=True)\n\n\n\nimport altair as alt\nfrom vega_datasets import data as vega_data\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=5, n_init=10)\nkmeans.fit(Conclusion[['ADAPTIVE','DEVELOPMENT','Adaptivity']])\nConclusion['label'] = kmeans.labels_\nConclusion.head()\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\n\n\n\nGEOID\nADAPTIVE\nDEVELOPMENT\nAdaptivity\ngeometry\nNAME_x\nTOPSIS_CALIBRATED\nlabel\n\n\n\n\n0\n36047059403\n0.584123\n0.539059\n0.178983\nPOLYGON ((-73.94905 40.59748, -73.94855 40.59753, -73.94812 40.59758, -73.94719 40.59768, -73.94623 40.59779, -73.94577 40.59540, -73.94674 40.59529, -73.94766 40.59519, -73.94859 40.59509, -73.94902 40.59735, -73.94905 40.59748))\nBlock Group 1; Census Tract 594.03; Kings County; New York\n0.426799\n1\n\n\n1\n36047059403\n0.584123\n0.539059\n0.198639\nPOLYGON ((-73.94952 40.59499, -73.94859 40.59509, -73.94766 40.59519, -73.94674 40.59529, -73.94577 40.59540, -73.94537 40.59328, -73.94634 40.59317, -73.94726 40.59307, -73.94819 40.59297, -73.94912 40.59287, -73.94952 40.59499))\nBlock Group 2; Census Tract 594.03; Kings County; New York\n0.433737\n1\n\n\n2\n36047059403\n0.584123\n0.539059\n0.300804\nPOLYGON ((-73.95101 40.59726, -73.94997 40.59738, -73.94905 40.59748, -73.94902 40.59735, -73.94859 40.59509, -73.94952 40.59499, -73.94912 40.59287, -73.95015 40.59275, -73.95055 40.59487, -73.95088 40.59661, -73.95101 40.59726))\nBlock Group 3; Census Tract 594.03; Kings County; New York\n0.469795\n1\n\n\n3\n36047059404\n0.487518\n0.442388\n0.202750\nPOLYGON ((-73.94912 40.59287, -73.94819 40.59297, -73.94726 40.59307, -73.94686 40.59095, -73.94646 40.58883, -73.94738 40.58873, -73.94831 40.58863, -73.94872 40.59075, -73.94912 40.59287))\nBlock Group 2; Census Tract 594.04; Kings County; New York\n0.372658\n1\n\n\n4\n36047059404\n0.487518\n0.442388\n0.181021\nPOLYGON ((-73.94726 40.59307, -73.94634 40.59317, -73.94537 40.59328, -73.94497 40.59116, -73.94401 40.59126, -73.94361 40.58915, -73.94457 40.58904, -73.94553 40.58893, -73.94646 40.58883, -73.94686 40.59095, -73.94726 40.59307))\nBlock Group 1; Census Tract 594.04; Kings County; New York\n0.364989\n1\n\n\n\n\n\n\n\n\ncolumns_to_keep_5 = ['ADAPTIVE','DEVELOPMENT',\"Adaptivity\",\"label\"]\nConclusion_Chart = Conclusion[columns_to_keep_5]\nConclusion_Chart = Conclusion_Chart.head(5000)\n\n\n\n\n\n\n\n\nADAPTIVE\nDEVELOPMENT\nAdaptivity\nlabel\n\n\n\n\n0\n0.584123\n0.539059\n0.178983\n1\n\n\n1\n0.584123\n0.539059\n0.198639\n1\n\n\n2\n0.584123\n0.539059\n0.300804\n1\n\n\n3\n0.487518\n0.442388\n0.202750\n1\n\n\n4\n0.487518\n0.442388\n0.181021\n1\n\n\n\n\n\n\n\n\n(\n    alt.Chart(Conclusion_Chart)\n    .mark_circle()\n    .encode(\n        alt.X(\"ADAPTIVE\", scale=alt.Scale(zero=False)),\n        alt.Y(\"DEVELOPMENT\", scale=alt.Scale(zero=False)),\n        size=\"Adaptivity\",\n        color=alt.Color(\"label\", scale=alt.Scale(scheme=\"viridis\")),\n        tooltip=list(Conclusion_Chart.columns),\n    )\n    .properties(width=400, height=300)\n    .interactive()\n)\n\n\n\n\n\n\n\n\nConclusion.plot(column='label', legend=True)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\n\nElderly_People = NYC_demo_final.to_crs(epsg=3857).hvplot(\n    c=\"Households with 60+\",\n    frame_width=600,\n    frame_height=600,\n    alpha=0.7,\n    geo=True,\n    crs=3857,\n    line_width=0.3,\n    line_color='white',\n    cmap=\"viridis\",\n    hover_cols=[\"Households with 60+\"],\n)\nElderly_People\n\n\n\n\n\n  \n\n\n\n\n\nimport pandas as pd\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndf_1 = pd.read_csv('./Data/a.csv')\n\ntext = ' '.join(df_1['response'].dropna())\n\nwordcloud = WordCloud(width=800, height=800, \n                      background_color='white', \n                      min_font_size=10).generate(text)\n                       \nplt.figure(figsize=(8, 8), facecolor=None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad=0) \n  \nplt.show()\n\n\n\n\n\nROW_D = gpd.read_file('./Shapefiles/Detention.shp')\nROW_D.head()\n\n\n\n\n\n\n\n\nassembly_d\nasset_area\nasset_id\nasset_leng\nasset_type\nasset_widt\nasset_x_co\nasset_y_co\nbbl\nborough\ncity_counc\ncommunity_\nconstruc_1\nconstructi\ndep_cont_1\ndep_contra\ngi_feature\ngi_id\nnyc_waters\noutfall\nprogram_ar\nproject_na\nrow_onsite\nsecondary_\nsewer_type\nstatus\nstatus_gro\ntree_commo\ntree_latin\ngeometry\n\n\n\n\n0\n52.0\n1092.0\n106022.0\n0.0\nSubsurface Detention System\n0.0\n9.887021e+05\n187744.73807\n3.003940e+09\nBrooklyn\n33.0\n306.0\n1\nGI-CONS-1\n1\nOGI-DESIGN-1-OS7\nNaN\nWG-U2\nGowanus Canal\nRH-034\nPublic Onsite\nWyckoff Gardens\nOnsite\n0.0\nCombined\nIn Construction\nIn Construction\nNaN\nNaN\nPOINT (-73.98395 40.68199)\n\n\n1\n52.0\n560.0\n106044.0\n0.0\nSubsurface Detention System\n0.0\n9.869173e+05\n188813.67431\n3.003970e+09\nBrooklyn\n33.0\n306.0\n1\nGI-CONS-1\n1\nOGI-DESIGN-1-OS1\nNaN\nBP-US1\nGowanus Canal\nRH-034\nPublic Onsite\nBoerum Park\nOnsite\n0.0\nCombined\nIn Construction\nIn Construction\nNaN\nNaN\nPOINT (-73.99038 40.68493)\n\n\n2\n52.0\n1388.0\n106049.0\n0.0\nSubsurface Detention System\n0.0\n9.853902e+05\n187550.45420\n3.004420e+09\nBrooklyn\n39.0\n306.0\n1\nGI-CONS-1\n1\nOGI-DESIGN-1-OS2\nNaN\nCP-US-BF\nGowanus Canal\nRH-034\nPublic Onsite\nCarroll Park\nOnsite\n0.0\nCombined\nIn Construction\nIn Construction\nNaN\nNaN\nPOINT (-73.99589 40.68146)\n\n\n3\n28.0\n504.0\n106085.0\n0.0\nSubsurface Detention System\n0.0\n1.019317e+06\n198028.13250\n4.037960e+09\nQueens\n30.0\n405.0\n1\nGI-CONS-1\n3\nOGI-DESIGN-1-OS6\nNaN\nMVP-US-2\nNewtown Creek\nNCB-083\nPublic Onsite\nMiddle Village Playground\nOnsite\n0.0\nCombined\nIn Construction\nIn Construction\nNaN\nNaN\nPOINT (-73.87351 40.71015)\n\n\n4\n37.0\n1773.0\n106090.0\n0.0\nSubsurface Detention System\n0.0\n1.010978e+06\n196031.50308\n4.034800e+09\nQueens\n30.0\n405.0\n1\nGI-CONS-1\n3\nOGI-DESIGN-1-OS9\nNaN\nRP-US-3\nNewtown Creek\nNCB-083\nPublic Onsite\nRosemarys Playground\nOnsite\n0.0\nCombined\nIn Construction\nIn Construction\nNaN\nNaN\nPOINT (-73.90360 40.70470)\n\n\n\n\n\n\n\n\n\nROW_D.to_crs(epsg=3857).hvplot(\n    frame_width=600,\n    frame_height=600,\n    geo=True,\n    crs=3857,\n    tiles='CartoLight',\n    cmap=\"viridis\",\n    hover_cols=[\"asset_area\"],\n)"
  },
  {
    "objectID": "analysis/Infrastructure Capacity and Development Capacity.html",
    "href": "analysis/Infrastructure Capacity and Development Capacity.html",
    "title": "Infrastructure Capacity and Development Capacity",
    "section": "",
    "text": "Our assessment consists of three sub-layers: Existing Green Infrastructure, Existing capacity for development and Existing vegetation coverage. The Right of Way Green Infrastructure is a project of NYC, which regularly receives grants for extension and maintenance. Green infrastructure collects stormwater from streets, sidewalks, and other hard surfaces before it can enter the sewer system or cause local flooding. By reducing the amount of stormwater that flows into the Sewer System, green infrastructure helps prevent Sewer Overflows and improves the health of local waterways (NYC DEP, 2022). The dataset consists of three types of ROW GI, which are retention, storage and infiltration. Each of them is assigned a different weight and spatial density is calculated before normalization. The weight is generated from residents’ responses to DEP, as residents tend to complain about low-capacity GI in workshop sessions.\nCapacity redundancy for development is a factor reflecting the ability of an area to be densified and diversified. Zoning code and housing unit density combined with vacancy rate are used to calculate the basic raster layer (AHS, 2021), which will be added to a normalized cost distance analysis of bus and train accessibility. The current vegetation coverage is a combination of land cover data and NDVI values, showing the ability to adapt to extra amounts of water. These criteria are developed with panel discussion results.\n\n\nCode\n    import pygris\n    NYC_county_code = [\"005\",\"047\",\"061\",\"081\",\"085\"]\n    NY_state_code = \"36\"\n    NYC_block_groups = pygris.block_groups(\n    state=NY_state_code, county=NYC_county_code, year=2022\n)\n    import geopandas as gpd\n    import pandas as pd\n    from matplotlib import pyplot as plt\n    ROW_D = gpd.read_file('./Shapefiles/Detention.shp')\n    fig, ax = plt.subplots(figsize=(10, 10))\n    NYC_block_groups.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=0.3)\n    ROW_D.plot(column=\"asset_area\", legend=False, ax=ax)\n\n\n&lt;Axes: &gt;\nDetention Green Infrastructure\n\n\n\n\n\nSubsurface Detention Systems with infiltration capability provide temporary storage of stormwater runoff underground. These systems have an open-bottom and can incorporate perforated pipe and stormwater chambers for added detention volume. Systems are primarily designed with a gravel bed that stores water until it can infiltrate into the ground.\n\n\nCode\n    ROW_S = gpd.read_file('./Shapefiles/storage.shp')\n    fig, ax = plt.subplots(figsize=(10, 10))\n    NYC_block_groups.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=0.3)\n    ROW_S.plot(column=\"asset_area\", legend=False, ax=ax)\n\n\n&lt;Axes: &gt;\nStorage Green Infrastructure\n\n\n\n\n\nInfiltration Basins are designed to store rain water beneath a surface that closely mimics its surroundings, like grass or concrete. They are similar in functionality to Rain Gardens. The inlet opening on the curb face collects the stormwater, which fills a chamber, or ‘sump.’ Once the sump is partially filled, openings on its walls feed into pipes, which convey the stormwater to an underlying stone layer; the stormwater then seeps into the ground underneath in a process called “infiltration.” Download our Green Infrastructure Infiltration Basin Design.\n\n\nCode\n    ROW_I = gpd.read_file('./Shapefiles/Infiltration.shp')\n    fig, ax = plt.subplots(figsize=(10, 10))\n    NYC_block_groups.plot(ax=ax, facecolor=\"none\", edgecolor=\"gray\", linewidth=0.3)\n    ROW_I.plot(column=\"asset_area\", legend=False, ax=ax)\n\n\n&lt;Axes: &gt;\nInfiltration Green Infrastructure\n\n\n\n\n\nStormwater Greenstreets, like Rain Gardens, are planted areas designed to collect and manage stormwater that runs off the streets and sidewalks. However Stormwater Greenstreets are typically constructed in the roadway, are usually larger than rain gardens, and have varying lengths, widths and soil depths based on the characteristics of the existing roadway.\n:::  :::\nA municipal separate storm sewer system (MS4) is a publicly-owned conveyance or system of conveyances (including but not limited to streets, ditches, catch basins, curbs, gutters, and storm drains) that is designed or used for collecting or conveying stormwater and that discharges to surface waters of the State. Separate storm sewers carry stormwater runoff directly to local waterbodies and serve approximately 30–40% of New York City.\nAs stormwater flows over streets and other impervious surfaces, it sweeps up pollutants such as oils, chemicals, pathogens, and sediments. In separate sewer areas, this pollution is carried by stormwater and discharged directly into local waterways. This can have a negative impact on water quality and recreational uses.\nKernel Density of each kind of Green Infrastructure is calculated in ArcGIS, then overlaid with Land Cover and MS4 areas rasterized.\nSimilarly, Transit access are representd by cost distance, which is calculated in ArcGIS with land cover as cost raster. Job assessment and land cover type are also taken into account. These results will be shown in next part, after housing database introduction."
  },
  {
    "objectID": "analysis/Housing Database and Community Adaptivity.html",
    "href": "analysis/Housing Database and Community Adaptivity.html",
    "title": "Housing Database and Community Adaptivity",
    "section": "",
    "text": "Community-based Adaptivity index is based on Rebuild by Design’s Climate Displacement in New York City report (Rebuild by Design, 2022). Moreover, we focus on the ownership rate and people within vulnerable Age Group, as displacement causes larger losses to homeowners and people older than 65 or younger than 15.\nTherefore, this index is determined by six demographics and housing-related criteria, which measures how an area is subject to storm-related asset loss and life-threatening situations and leans more to social impact than the previous factors. Data are acquired from ACS API (ACS, 2022). They are:\nHouseholds with one or more people 60 years and over; Vacancy; Renter Occupation; Total Population; Median household income; Median year built.\n\n\nCode\nimport pygris\nimport geopandas as gpd\nimport numpy as np\nimport pandas as pd\n\nimport requests\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport holoviews as hv\nimport hvplot.pandas\nimport matplotlib.font_manager as font_manager\n\nimport cenpy\n\npd.options.display.max_columns = 999\npd.options.display.max_colwidth = None\n\navailable = cenpy.explorer.available()\n\nacs = available.filter(regex=\"^ACS\", axis=0)\n\navailable.filter(regex=\"^ACSDT5Y\", axis=0)\n\nacs = cenpy.remote.APIConnection(\"ACSDT5Y2022\")\n\nvariables = [\n    \"NAME\",\n    \"B11006_002E\", #Households with one or more people 60 years and over\n    \"B25002_003E\", #Vacancy\n    \"B25003_003E\", #Renter Occupation\n    \"B01003_001E\", #Total Population\n    \"B19013_001E\", #Median household income\n    \"B25035_001E\", #Median year built\n]\n\nNYC_county_code = [\"005\",\"047\",\"061\",\"081\",\"085\"]\nNY_state_code = \"36\"\n\ncounty_codes = \",\".join(NYC_county_code)\n\nNYC_demo_data = acs.query(\n    cols=variables,\n    geo_unit=\"block group:*\",\n    geo_filter={\"state\": NY_state_code, \"county\": county_codes, \"tract\": \"*\"},\n)\n\nNYC_block_groups = pygris.block_groups(\n    state=NY_state_code, county=NYC_county_code, year=2022\n)\n\nNYC_demo_final = NYC_block_groups.merge(\n    NYC_demo_data,\n    left_on=[\"STATEFP\", \"COUNTYFP\", \"TRACTCE\", \"BLKGRPCE\"],\n    right_on=[\"state\", \"county\", \"tract\", \"block group\"],\n)\n\nNYC_demo_final.rename(columns={\n    \"B11006_002E\": \"Households with 60+\",\n    \"B25002_003E\": \"Vacancy\",\n    \"B25003_003E\": \"Renter Occupation\",\n    \"B01003_001E\": \"Total Population\",\n    \"B19013_001E\": \"Median Household Income\",\n    \"B25035_001E\": \"Median Year Built\"\n}, inplace=True)\n\nNYC_demo_final['Households with 60+'] = pd.to_numeric(NYC_demo_final['Households with 60+'], errors='coerce').fillna(0).astype(int)\nNYC_demo_final['Vacancy'] = pd.to_numeric(NYC_demo_final['Vacancy'], errors='coerce').fillna(0).astype(int)\nNYC_demo_final['Renter Occupation'] = pd.to_numeric(NYC_demo_final['Renter Occupation'], errors='coerce').fillna(0).astype(int)\nNYC_demo_final['Total Population'] = pd.to_numeric(NYC_demo_final['Total Population'], errors='coerce').fillna(0).astype(int)\n\nNYC_demo_final['Median Household Income'] = pd.to_numeric(NYC_demo_final['Median Household Income'], errors='coerce').fillna(0).astype(int)\nmedian1 = NYC_demo_final['Median Household Income'].median()\nNYC_demo_final['Median Household Income'] = NYC_demo_final['Median Household Income'].mask(NYC_demo_final['Median Household Income'] &lt; 0, median1)\n\nNYC_demo_final['Median Year Built'] = pd.to_numeric(NYC_demo_final['Median Year Built'], errors='coerce').fillna(0).astype(int)\nmedian2 = NYC_demo_final['Median Year Built'].median()\nNYC_demo_final['Median Year Built'] = NYC_demo_final['Median Year Built'].mask(NYC_demo_final['Median Year Built'] &lt; 0, median2)\n\n\n\n\n\n\n\n\n\n\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:39: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_dist(x, y):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:165: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def get_faces(triangle):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:199: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def build_faces(faces, triangles_is, num_triangles, num_faces_single):\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\libpysal\\cg\\alpha_shapes.py:261: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n  def nb_mask_faces(mask, faces):\n\n\n\n\nCode\nNYC_demo_final.plot(column='Households with 60+', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nHouseholds with 60+\n\n\n\n\n\n\nCode\nNYC_demo_final.plot(column='Vacancy', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nVacancy\n\n\n\n\n\n\nCode\nNYC_demo_final.plot(column='Renter Occupation', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nRenter Occupation\n\n\n\n\n\n\nCode\nNYC_demo_final.plot(column='Total Population', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nTotal Population\n\n\n\n\n\n\nCode\nNYC_demo_final.plot(column='Median Household Income', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nMedian Household Income\n\n\n\n\n\n\nCode\nNYC_demo_final.plot(column='Median Year Built', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nMedian Year Built\n\n\n\n\nNext, we are going to normalize these data. We generally expect less elderly people, Lower ownershiprate, higher vacancy, higher Justice 40 qualification rate represented by lower income, newer houses and smaller population size.\n\n\nCode\nfrom scipy.stats import gmean\n\nNYC_demo_final_Normalized = NYC_demo_final\n\nNYC_demo_final_Normalized['Households with 60+'] = NYC_demo_final_Normalized['Households with 60+']/-1000\nNYC_demo_final_Normalized['Vacancy'] = NYC_demo_final_Normalized['Vacancy']/400\nNYC_demo_final_Normalized['Renter Occupation'] = NYC_demo_final_Normalized['Renter Occupation']/1500\nNYC_demo_final_Normalized['Total Population'] = NYC_demo_final_Normalized['Total Population']/-6000\nNYC_demo_final_Normalized['Median Household Income'] = NYC_demo_final_Normalized['Median Household Income']/-200000\nNYC_demo_final_Normalized['Median Year Built'] = (NYC_demo_final_Normalized['Median Year Built'] - 1900)/122\n\nNYC_demo_final_Normalized.index = NYC_demo_final_Normalized['GEOID']\ncolumns_to_keep = [\"Households with 60+\",\"Vacancy\",\"Renter Occupation\",\"Total Population\",\"Median Household Income\",\"Median Year Built\"]\n                                   \nnew_df = NYC_demo_final_Normalized[columns_to_keep]\n\nk = -(1/np.log(new_df.shape[0]))\n\ndef entropy(X):\n    return (X*np.log(X)).sum()*k\n\nentropy = new_df.apply(entropy)\n\ndod = 1 - entropy\n\nw = dod/dod.sum()\nw.sort_values(ascending = False)\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n\n\nMedian Year Built          0.455488\nRenter Occupation          0.341362\nVacancy                    0.208312\nHouseholds with 60+       -0.001721\nTotal Population          -0.001721\nMedian Household Income   -0.001721\ndtype: float64\n\n\nTOPSIS, standing for Technique for Order of Preference by Similarity to Ideal Solution, is a method used in multi-criteria decision analysis purposed by Hwang et al. (Yoon & Hwang, 1995). It involves comparing a set of alternatives against a defined set of criteria. This method finds widespread application in various industries within the business sector, being particularly useful whenever there’s a need to make an analytical decision grounded in collected data. (Lai, et al., 1994). The entropy weight method is an effective method to accurately weigh the relative importance of the identified criteria for TOPSIS computation, the base of which is the volume of information to calculate the index’s weight (Dehdasht, et al., 2020).\nListed above is a set of Entropy-TOPSIS calibrated weight based on pattern of data. Among these variables, Median Year Built,Renter Occupation and Vacancy are of significant importance. So we are going to do a weighted overlay.\n\n\nCode\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized['Vacancy']*0.198211\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.461299*NYC_demo_final_Normalized['Median Year Built']\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.345718*NYC_demo_final_Normalized['Renter Occupation']\ncolumns_to_keep_2 = [\"GEOID\",\"Adaptivity\",\"geometry\",\"NAME\"]\nNYC_Adaptive_Capacity = NYC_demo_final_Normalized[columns_to_keep_2]\n\n\nNow, let’s join with the previous two criteria.\n\n\nCode\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized['Vacancy']*0.198211\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.461299*NYC_demo_final_Normalized['Median Year Built']\nNYC_demo_final_Normalized[\"Adaptivity\"] = NYC_demo_final_Normalized[\"Adaptivity\"] + 0.345718*NYC_demo_final_Normalized['Renter Occupation']\ncolumns_to_keep_2 = [\"GEOID\",\"Adaptivity\",\"geometry\",\"NAME\"]\nNYC_Adaptive_Capacity = NYC_demo_final_Normalized[columns_to_keep_2]\nNYC_Adaptive_Capacity.reset_index(inplace=True, drop=True)\n\nCriteria1_2 = pd.read_csv('./Data/Adaptive_And_Development.csv')\nNYC_Adaptive_Capacity['GEOID'] = NYC_Adaptive_Capacity['GEOID'].astype(str)\nNYC_Adaptive_Capacity['GEOID'] = NYC_Adaptive_Capacity['GEOID'].apply(lambda x: x[:-1])\nCriteria1_2['GEOID'] = Criteria1_2['GEOID'].astype(str)\n\nAdaptive_Capacity = NYC_Adaptive_Capacity.merge(Criteria1_2, on='GEOID')\nmax_value_1 = Adaptive_Capacity['ADAPTIVE'].max()\nmax_value_2 = Adaptive_Capacity['DEVELOPMENT'].max()\nAdaptive_Capacity['ADAPTIVE'] = Adaptive_Capacity['ADAPTIVE']/ max_value_1\nAdaptive_Capacity['DEVELOPMENT'] = Adaptive_Capacity['DEVELOPMENT']/ max_value_2\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\nCode\nAdaptive_Capacity.plot(column='ADAPTIVE', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nInfrastructure Index\n\n\n\n\n\n\nCode\nAdaptive_Capacity.plot(column='DEVELOPMENT', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nDevelopment Index\n\n\n\n\n\n\nCode\nAdaptive_Capacity.plot(column='Adaptivity', legend=True, cmap='viridis')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nAdaptivity Index\n\n\n\n\nNow, we apply again the entropy-TOPSIS method to calibrate the final weight. We can explore some interesting patterns from here.\n\n\nCode\ncolumns_to_keep_3 = ['ADAPTIVE','DEVELOPMENT',\"Adaptivity\"]\nFinal_TOPSIS = Adaptive_Capacity[columns_to_keep_3]\n\nk = -(1/np.log(Final_TOPSIS.shape[0]))\n\ndef entropy(X):\n    return (X*np.log(X)).sum()*k\n\nentropy = Final_TOPSIS.apply(entropy)\n\ndod = 1 - entropy\n\nw = dod/dod.sum()\nw.sort_values(ascending = False)\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\pandas\\core\\arraylike.py:402: RuntimeWarning: divide by zero encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n\n\nAdaptivity     0.353072\nADAPTIVE       0.328961\nDEVELOPMENT    0.317967\ndtype: float64\n\n\nNow we have the new calibrated weight. We can move on to the next step.\n\n\nCode\ncolumns_to_keep_4 = [\"GEOID\",'ADAPTIVE','DEVELOPMENT',\"Adaptivity\",\"geometry\",\"NAME_x\"]\nConclusion = Adaptive_Capacity[columns_to_keep_4]\nConclusion[\"TOPSIS_CALIBRATED\"]=Conclusion[\"Adaptivity\"]*0.352945 + Conclusion[\n    \"ADAPTIVE\"]*0.329026 + Conclusion[\"DEVELOPMENT\"]*0.318029\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\nThe conclusion dataframe is here. The next step is K-means grouping in two ways, thus checking if calibrated weight reflect the types of communities well.\n\n\nCode\nvariables = [\n    \"ADAPTIVE\",\n    \"DEVELOPMENT\",\n    \"Adaptivity\",\n]\n\nsns.set_context(\"notebook\", font_scale=1.5)\n\npalette_choice = 'crest'\nsns.pairplot(\n    Conclusion[variables].dropna(),\n    palette=palette_choice,\n    plot_kws=dict(alpha=0.5, edgecolor=\"none\"),\n)\n\n\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1507: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=vector, **plot_kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:1609: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n  func(x=x, y=y, **kwargs)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n  self._figure.tight_layout(*args, **kwargs)\n\n\n\n\n\nCriteria Correlation\n\n\n\n\n\n\nCode\nConclusion.fillna(0, inplace=True)\nimport altair as alt\nfrom vega_datasets import data as vega_data\nfrom sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=5, n_init=10)\nkmeans.fit(Conclusion[['ADAPTIVE','DEVELOPMENT','Adaptivity']])\nConclusion['label'] = kmeans.labels_\ncolumns_to_keep_5 = ['ADAPTIVE','DEVELOPMENT',\"Adaptivity\",\"label\"]\nConclusion_Chart = Conclusion[columns_to_keep_5]\nConclusion_Chart = Conclusion_Chart.head(5000)\n(\n    alt.Chart(Conclusion_Chart)\n    .mark_circle()\n    .encode(\n        alt.X(\"ADAPTIVE\", scale=alt.Scale(zero=False)),\n        alt.Y(\"DEVELOPMENT\", scale=alt.Scale(zero=False)),\n        size=\"Adaptivity\",\n        color=alt.Color(\"label\", scale=alt.Scale(scheme=\"viridis\")),\n        tooltip=list(Conclusion_Chart.columns),\n    )\n    .properties(width=400, height=300)\n    .interactive()\n)\n\n\nC:\\Users\\Josh Williamson\\AppData\\Local\\Temp\\ipykernel_23836\\890882115.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  Conclusion.fillna(0, inplace=True)\nD:\\Mamba\\envs\\musa-550-fall-2023\\lib\\site-packages\\geopandas\\geodataframe.py:1538: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  super().__setitem__(key, value)\n\n\n\n\n\n\nK-Means Clustering\n\n\n\n\nCode\nConclusion.plot(column='label', legend=True)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nClustering Distribution\n\n\n\n\n\n\nCode\nConclusion.plot(column='TOPSIS_CALIBRATED', legend=True)\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.show()\n\n\n\n\n\nTOPSIS Distribution"
  },
  {
    "objectID": "analysis/5-OSM.html",
    "href": "analysis/5-OSM.html",
    "title": "Adaptive Capacity of New York City",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport hvplot.pandas\nfrom matplotlib import pyplot as plt\n\npd.options.display.max_columns = 999\n\nnp.seterr(invalid=\"ignore\");"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html",
    "href": "analysis/3-altair-hvplot.html",
    "title": "Altair and Hvplot Charts",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive charts produced using Altair and hvPlot."
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-altair",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in Altair",
    "text": "Example: Measles Incidence in Altair\nFirst, let’s load the data for measles incidence in wide format:\n\n\nCode\nurl = \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/measles_incidence.csv\"\ndata = pd.read_csv(url, skiprows=2, na_values=\"-\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nWEEK\nALABAMA\nALASKA\nARIZONA\nARKANSAS\nCALIFORNIA\nCOLORADO\nCONNECTICUT\nDELAWARE\n...\nSOUTH DAKOTA\nTENNESSEE\nTEXAS\nUTAH\nVERMONT\nVIRGINIA\nWASHINGTON\nWEST VIRGINIA\nWISCONSIN\nWYOMING\n\n\n\n\n0\n1928\n1\n3.67\nNaN\n1.90\n4.11\n1.38\n8.38\n4.50\n8.58\n...\n5.69\n22.03\n1.18\n0.4\n0.28\nNaN\n14.83\n3.36\n1.54\n0.91\n\n\n1\n1928\n2\n6.25\nNaN\n6.40\n9.91\n1.80\n6.02\n9.00\n7.30\n...\n6.57\n16.96\n0.63\nNaN\n0.56\nNaN\n17.34\n4.19\n0.96\nNaN\n\n\n2\n1928\n3\n7.95\nNaN\n4.50\n11.15\n1.31\n2.86\n8.81\n15.88\n...\n2.04\n24.66\n0.62\n0.2\n1.12\nNaN\n15.67\n4.19\n4.79\n1.36\n\n\n3\n1928\n4\n12.58\nNaN\n1.90\n13.75\n1.87\n13.71\n10.40\n4.29\n...\n2.19\n18.86\n0.37\n0.2\n6.70\nNaN\n12.77\n4.66\n1.64\n3.64\n\n\n4\n1928\n5\n8.03\nNaN\n0.47\n20.79\n2.38\n5.13\n16.80\n5.58\n...\n3.94\n20.05\n1.57\n0.4\n6.70\nNaN\n18.83\n7.37\n2.91\n0.91\n\n\n\n\n5 rows × 53 columns\n\n\n\nThen, use the pandas.melt() function to convert it to tidy format:\n\n\nCode\nannual = data.drop(\"WEEK\", axis=1)\nmeasles = annual.groupby(\"YEAR\").sum().reset_index()\nmeasles = measles.melt(id_vars=\"YEAR\", var_name=\"state\", value_name=\"incidence\")\n\n\n\n\n\n\n\n\n\n\n\nYEAR\nstate\nincidence\n\n\n\n\n0\n1928\nALABAMA\n334.99\n\n\n1\n1929\nALABAMA\n111.93\n\n\n2\n1930\nALABAMA\n157.00\n\n\n3\n1931\nALABAMA\n337.29\n\n\n4\n1932\nALABAMA\n10.21\n\n\n\n\n\n\n\nFinally, load altair:\n\nimport altair as alt\n\nAnd generate our final data viz:\n\n# use a custom color map\ncolormap = alt.Scale(\n    domain=[0, 100, 200, 300, 1000, 3000],\n    range=[\n        \"#F0F8FF\",\n        \"cornflowerblue\",\n        \"mediumseagreen\",\n        \"#FFEE00\",\n        \"darkorange\",\n        \"firebrick\",\n    ],\n    type=\"sqrt\",\n)\n\n# Vertical line for vaccination year\nthreshold = pd.DataFrame([{\"threshold\": 1963}])\n\n# plot YEAR vs state, colored by incidence\nchart = (\n    alt.Chart(measles)\n    .mark_rect()\n    .encode(\n        x=alt.X(\"YEAR:O\", axis=alt.Axis(title=None, ticks=False)),\n        y=alt.Y(\"state:N\", axis=alt.Axis(title=None, ticks=False)),\n        color=alt.Color(\"incidence:Q\", sort=\"ascending\", scale=colormap, legend=None),\n        tooltip=[\"state\", \"YEAR\", \"incidence\"],\n    )\n    .properties(width=650, height=500)\n)\n\nrule = alt.Chart(threshold).mark_rule(strokeWidth=4).encode(x=\"threshold:O\")\n\nout = chart + rule\nout"
  },
  {
    "objectID": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "href": "analysis/3-altair-hvplot.html#example-measles-incidence-in-hvplot",
    "title": "Altair and Hvplot Charts",
    "section": "Example: Measles Incidence in hvplot",
    "text": "Example: Measles Incidence in hvplot\n\n\n\n\n\n\n\n\n\n\n\n\nGenerate the same data viz in hvplot:\n\n# Make the heatmap with hvplot\nheatmap = measles.hvplot.heatmap(\n    x=\"YEAR\",\n    y=\"state\",\n    C=\"incidence\", # color each square by the incidence\n    reduce_function=np.sum, # sum the incidence for each state/year\n    frame_height=450,\n    frame_width=600,\n    flip_yaxis=True,\n    rot=90,\n    colorbar=False,\n    cmap=\"viridis\",\n    xlabel=\"\",\n    ylabel=\"\",\n)\n\n# Some additional formatting using holoviews \n# For more info: http://holoviews.org/user_guide/Customizing_Plots.html\nheatmap = heatmap.redim(state=\"State\", YEAR=\"Year\")\nheatmap = heatmap.opts(fontsize={\"xticks\": 0, \"yticks\": 6}, toolbar=\"above\")\nheatmap"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "My name is Xinchen Wei, a Master’s student in Landscape Architecture & Regional Planning at the Weitzman School of Design, having finished my undergraduate studies in Tsinghua University. I am in the Urban Resilience Certificate program and working as a Research Assistant with Matthijs Bouw on Making Room For The Water project. My major focuses are managed retreat, storm surges, and national park studies. You can find more information about me on my personal website."
  },
  {
    "objectID": "analysis/2-static-image.html",
    "href": "analysis/2-static-image.html",
    "title": "Showing static visualizations",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and demonstrates how to generate static visualizations with matplotlib, pandas, and seaborn.\nStart by importing the packages we need:\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nLoad the “Palmer penguins” dataset from week 2:\n# Load data on Palmer penguins\npenguins = pd.read_csv(\"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-2/main/data/penguins.csv\")\n# Show the first ten rows\npenguins.head(n=10)    \n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n5\nAdelie\nTorgersen\n39.3\n20.6\n190.0\n3650.0\nmale\n2007\n\n\n6\nAdelie\nTorgersen\n38.9\n17.8\n181.0\n3625.0\nfemale\n2007\n\n\n7\nAdelie\nTorgersen\n39.2\n19.6\n195.0\n4675.0\nmale\n2007\n\n\n8\nAdelie\nTorgersen\n34.1\n18.1\n193.0\n3475.0\nNaN\n2007\n\n\n9\nAdelie\nTorgersen\n42.0\n20.2\n190.0\n4250.0\nNaN\n2007"
  },
  {
    "objectID": "analysis/2-static-image.html#a-simple-visualization-3-different-ways",
    "href": "analysis/2-static-image.html#a-simple-visualization-3-different-ways",
    "title": "Showing static visualizations",
    "section": "A simple visualization, 3 different ways",
    "text": "A simple visualization, 3 different ways\n\nI want to scatter flipper length vs. bill length, colored by the penguin species\n\n\nUsing matplotlib\n\n# Setup a dict to hold colors for each species\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Initialize the figure \"fig\" and axes \"ax\"\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Group the data frame by species and loop over each group\n# NOTE: \"group\" will be the dataframe holding the data for \"species\"\nfor species, group_df in penguins.groupby(\"species\"):\n\n    # Plot flipper length vs bill length for this group\n    # Note: we are adding this plot to the existing \"ax\" object\n    ax.scatter(\n        group_df[\"flipper_length_mm\"],\n        group_df[\"bill_length_mm\"],\n        marker=\"o\",\n        label=species,\n        color=color_map[species],\n        alpha=0.75,\n        zorder=10\n    )\n\n# Plotting is done...format the axes!\n\n## Add a legend to the axes\nax.legend(loc=\"best\")\n\n## Add x-axis and y-axis labels\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\n\n## Add the grid of lines\nax.grid(True);\n\n\n\n\n\n\nHow about in pandas?\nDataFrames have a built-in “plot” function that can make all of the basic type of matplotlib plots!\nFirst, we need to add a new “color” column specifying the color to use for each species type.\nUse the pd.replace() function: it use a dict to replace values in a DataFrame column.\n\n# Calculate a list of colors\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\n\n# Map species name to color \npenguins[\"color\"] = penguins[\"species\"].replace(color_map)\n\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\ncolor\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n#1f77b4\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n#1f77b4\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n#1f77b4\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n#1f77b4\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n#1f77b4\n\n\n\n\n\n\n\nNow plot!\n\n# Same as before: Start by initializing the figure and axes\nfig, myAxes = plt.subplots(figsize=(10, 6))\n\n# Scatter plot two columns, colored by third\n# Use the built-in pandas plot.scatter function\npenguins.plot.scatter(\n    x=\"flipper_length_mm\",\n    y=\"bill_length_mm\",\n    c=\"color\",\n    alpha=0.75,\n    ax=myAxes, # IMPORTANT: Make sure to plot on the axes object we created already!\n    zorder=10\n)\n\n# Format the axes finally\nmyAxes.set_xlabel(\"Flipper Length (mm)\")\nmyAxes.set_ylabel(\"Bill Length (mm)\")\nmyAxes.grid(True);\n\n\n\n\nNote: no easy way to get legend added to the plot in this case…\n\n\nSeaborn: statistical data visualization\nSeaborn is designed to plot two columns colored by a third column…\n\n# Initialize the figure and axes\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# style keywords as dict\ncolor_map = {\"Adelie\": \"#1f77b4\", \"Gentoo\": \"#ff7f0e\", \"Chinstrap\": \"#D62728\"}\nstyle = dict(palette=color_map, s=60, edgecolor=\"none\", alpha=0.75, zorder=10)\n\n# use the scatterplot() function\nsns.scatterplot(\n    x=\"flipper_length_mm\",  # the x column\n    y=\"bill_length_mm\",  # the y column\n    hue=\"species\",  # the third dimension (color)\n    data=penguins,  # pass in the data\n    ax=ax,  # plot on the axes object we made\n    **style  # add our style keywords\n)\n\n# Format with matplotlib commands\nax.set_xlabel(\"Flipper Length (mm)\")\nax.set_ylabel(\"Bill Length (mm)\")\nax.grid(True)\nax.legend(loc=\"best\");"
  },
  {
    "objectID": "analysis/4-folium.html",
    "href": "analysis/4-folium.html",
    "title": "Interactive Maps with Folium",
    "section": "",
    "text": "This page is generated from a Jupyter notebook and shows examples of embedding interactive maps produced using Folium."
  },
  {
    "objectID": "analysis/4-folium.html#finding-the-shortest-route",
    "href": "analysis/4-folium.html#finding-the-shortest-route",
    "title": "Interactive Maps with Folium",
    "section": "Finding the shortest route",
    "text": "Finding the shortest route\nThis example finds the shortest route between the Art Musuem and the Liberty Bell using osmnx.\n\nimport osmnx as ox\n\nFirst, identify the lat/lng coordinates for our places of interest. Use osmnx to download the geometries for the Libery Bell and Art Museum.\n\nphilly_tourism = ox.features_from_place(\"Philadelphia, PA\", tags={\"tourism\": True})\n\n\nart_museum = philly_tourism.query(\"name == 'Philadelphia Museum of Art'\").squeeze()\n\nart_museum.geometry\n\n\n\n\n\nliberty_bell = philly_tourism.query(\"name == 'Liberty Bell'\").squeeze()\n\nliberty_bell.geometry\n\n\n\n\nNow, extract the lat and lng coordinates\nFor the Art Museum geometry, we can use the .geometry.centroid attribute to calculate the centroid of the building footprint.\n\nliberty_bell_x = liberty_bell.geometry.x\nliberty_bell_y = liberty_bell.geometry.y\n\n\nart_museum_x = art_museum.geometry.centroid.x\nart_museum_y = art_museum.geometry.centroid.y\n\nNext, use osmnx to download the street graph around Center City.\n\nG_cc = ox.graph_from_address(\n    \"City Hall, Philadelphia, USA\", dist=1500, network_type=\"drive\"\n)\n\nNext, identify the nodes in the graph closest to our points of interest.\n\n# Get the origin node (Liberty Bell)\norig_node = ox.nearest_nodes(G_cc, liberty_bell_x, liberty_bell_y)\n\n# Get the destination node (Art Musuem)\ndest_node = ox.nearest_nodes(G_cc, art_museum_x, art_museum_y)\n\nFind the shortest path, based on the distance of the edges:\n\n# Get the shortest path --&gt; just a list of node IDs\nroute = ox.shortest_path(G_cc, orig_node, dest_node, weight=\"length\")\n\nHow about an interactive version?\nosmnx has a helper function ox.utils_graph.route_to_gdf() to convert a route to a GeoDataFrame of edges.\n\nox.utils_graph.route_to_gdf(G_cc, route, weight=\"length\").explore(\n    tiles=\"cartodb positron\",\n    color=\"red\",\n)\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/4-folium.html#examining-trash-related-311-requests",
    "href": "analysis/4-folium.html#examining-trash-related-311-requests",
    "title": "Interactive Maps with Folium",
    "section": "Examining Trash-Related 311 Requests",
    "text": "Examining Trash-Related 311 Requests\nFirst, let’s load the dataset from a CSV file and convert to a GeoDataFrame:\n\n\nCode\n# Load the data from a CSV file into a pandas DataFrame\ntrash_requests_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/trash_311_requests_2020.csv\"\n)\n\n# Remove rows with missing geometry\ntrash_requests_df = trash_requests_df.dropna(subset=[\"lat\", \"lon\"])\n\n\n# Create our GeoDataFrame with geometry column created from lon/lat\ntrash_requests = gpd.GeoDataFrame(\n    trash_requests_df,\n    geometry=gpd.points_from_xy(trash_requests_df[\"lon\"], trash_requests_df[\"lat\"]),\n    crs=\"EPSG:4326\",\n)\n\n\nLoad neighborhoods and do the spatial join to associate a neighborhood with each ticket:\n\n\nCode\n# Load the neighborhoods\nneighborhoods = gpd.read_file(\n    \"https://raw.githubusercontent.com/MUSA-550-Fall-2023/week-4/main/data/zillow_neighborhoods.geojson\"\n)\n\n# Do the spatial join to add the \"ZillowName\" column\nrequests_with_hood = gpd.sjoin(\n    trash_requests,\n    neighborhoods.to_crs(trash_requests.crs),\n    predicate=\"within\",\n)\n\n\nLet’s explore the 311 requests in the Greenwich neighborhood of the city:\n\n# Extract out the point tickets for Greenwich\ngreenwich_tickets = requests_with_hood.query(\"ZillowName == 'Greenwich'\")\n\n\n# Get the neighborhood boundary for Greenwich\ngreenwich_geo = neighborhoods.query(\"ZillowName == 'Greenwich'\")\n\ngreenwich_geo.squeeze().geometry\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarto has callout blocks that you can use to emphasize content in different ways. This is a “Note” callout block. More info is available on the Quarto documentation.\n\n\nImport the packages we need:\n\nimport folium\nimport xyzservices\n\nCombine the tickets as markers and the neighborhood boundary on the same Folium map:\n\n# Plot the neighborhood boundary\nm = greenwich_geo.explore(\n    style_kwds={\"weight\": 4, \"color\": \"black\", \"fillColor\": \"none\"},\n    name=\"Neighborhood boundary\",\n    tiles=xyzservices.providers.CartoDB.Voyager,\n)\n\n\n# Add the individual tickets as circle markers and style them\ngreenwich_tickets.explore(\n    m=m,  # Add to the existing map!\n    marker_kwds={\"radius\": 7, \"fill\": True, \"color\": \"crimson\"},\n    marker_type=\"circle_marker\", # or 'marker' or 'circle'\n    name=\"Tickets\",\n)\n\n# Hse folium to add layer control\nfolium.LayerControl().add_to(m)\n\nm  # show map\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "analysis/Adaptive Capacity and Response Interpretation.html",
    "href": "analysis/Adaptive Capacity and Response Interpretation.html",
    "title": "Adaptive Capacity and Response Interpretation",
    "section": "",
    "text": "The history of land use in New York city is fraught with redlining and allowing environmental hazards to multiply in some communities, while keeping others safe. It is important to ensure that the community’s visions and historic needs are driving local, state, and federal policy. Workshops are conducted to develop recommendations for a community-informed long-term, stable, planned climate migration program that will center communities in the conversation about climate relocation (unlike unplanned responses after extreme weather events).\nThe Adaptive Capacity index is the final factor in Risk Assessment (Lyu, et al., 2019). Adaptive capacity plays a crucial role in the fields of vulnerability and resilience, yet it is frequently undervalued. By integrating insights from both vulnerability and resilience research, assessments of adaptive capacity can significantly contribute to the development of theory and practice in sustainability science. Such a comprehensive approach, blending elements from these related but distinct areas, enriches our understanding and application of adaptive strategies, ultimately enhancing the effectiveness of sustainability initiatives (Engle, 2011).\n\n\nCode\nimport pandas as pd\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\ndf_1 = pd.read_csv('./Data/a.csv')\n\ntext = ' '.join(df_1['response'].dropna())\n\nwordcloud = WordCloud(width=800, height=800, \n                      background_color='white', \n                      min_font_size=10).generate(text)\n                       \nplt.figure(figsize=(8, 8), facecolor=None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad=0) \n  \nplt.show()\n\n\n\n\n\nWord cloud analysis from symposium responses on Flood Mitigation Challenges\n\n\n\n\n\n\nCode\ndf_2 = pd.read_csv('./Data/b.csv')\n\ntext = ' '.join(df_2['response'].dropna())\n\nwordcloud = WordCloud(width=800, height=800, \n                      background_color='white', \n                      min_font_size=10).generate(text)\n                       \nplt.figure(figsize=(8, 8), facecolor=None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad=0) \n  \nplt.show()\n\n\n\n\n\nWord cloud analysis from symposium responses on Displacement and Migration Challenges\n\n\n\n\n\n\nCode\ndf_3 = pd.read_csv('./Data/c.csv')\n\ntext = ' '.join(df_3['response'].dropna())\n\nwordcloud = WordCloud(width=800, height=800, \n                      background_color='white', \n                      min_font_size=10).generate(text)\n                       \nplt.figure(figsize=(8, 8), facecolor=None) \nplt.imshow(wordcloud) \nplt.axis(\"off\") \nplt.tight_layout(pad=0) \n  \nplt.show()\n\n\n\n\n\nWord cloud analysis from symposium responses on Stakeholder Challenges\n\n\n\n\nThere are three main goals of this bottom-up process: to learn how to talk to communities about planning for anti-displacement, to build capacity within the community to understand how historic planning and future climate risk impact their neighborhood and how they can have agency over what happens to the neighborhood, to build an understanding of what people most care about in planning such that the short and long-term can be linked.\nFurthermore, panel discussions with participants interacting with other stakeholders, including DEP and FEMA, will provide more information on how residents perceive government work. These events are supposed to:\nDevelop recommendations for a community-informed long-term, stable, planned climate migration program that will center communities in the conversation about climate relocation (unlike unplanned responses after extreme weather events),\nInform NYS, NYC, and policy makers on how to discuss and design successful climate migration programs and expand their knowledge of the risk to communities, critical infrastructure, and utilities,\nIdentify how government and researchers can help communities balance the long-term challenges with the immediate concerns of their lives and livelihoods,\nIdentify how local governments can engage communities in conversations about land-use changes in ways that build trust and give residents agency over their decisions.\nOur findings reveal that stakeholders expect a greater share of responsibility from authorities and agencies, while public funding is also important. Buyout programs raise awareness about displacement, and people are concerned about alternative housing options and community structure. Lack of maintenance and communication between local representatives and government boards are considered as stakeholder challenges."
  },
  {
    "objectID": "analysis/index.html",
    "href": "analysis/index.html",
    "title": "Analysis",
    "section": "",
    "text": "Analysis\nThis section includes examples of technical analysis done using Jupyter notebooks. Each sub-section highlights different types of analyses and visualizations. In particular, it highlights that we can easily publish interactive visualizations produced with packages such as hvPlot, altair, or Folium, without losing any of the interactive features.\nThis final project will explore the evaluation process of the Adaptive Capacity Index, featuring with web-based data visualization. This analysis is derived from research project “Making Room for the Water” (https://rebuildbydesign.org/making-room-for-the-water/), but for the purpose of a final project, the research area is changed, and fields of interest are rearranged. The data source will be a combination of ACS API (REQUIREMENT 1) and zonal statistics exported from ArcGIS analysis. Local and online datasets will be combined using geospatial join, and data frame operations will be used to make the database tidier (REQUIREMENT 2). Different parameters from API will be divided into several indicator sets, which act as the index layer in the decision tree. These indexes is based on panel discussion in NYC rainproof symposium. In the panel discussion, we encouraged participants to indicate barriers, goals, responsibilities, and stakeholders. After analyzing the responses, we can determine how we are assessing the adaptive capacity, and how we are developing our strategy set. World cloud will be displayed to demonstrate stakeholders’ perspective of view. The development capacity index and the infrastructure index is processed in ArcGIS, with dataset from NYC Open Data and NYC DEP (REQUIREMENT 3). The demographic index will be evaluated based on ACS database, as different parameters will be input of TOPSIS approach, which determines the calibrated weight, then the index is generated from the process of weighed overlay. Then another level of TOPSIS calibration will combine the three indexes together, with an output of overall risk level, divided into 5 categories. For cross-reference, clustering analysis will also be performed based on the three indexes, and interactive charts will be utilized to demonstrate how the conclusion of clustering analysis may differ from a linear weighted sum of parameters (REQUIREMENT 4). This project is an individual project, and of all the possible requirements to satisfy, it should qualify with 4, while 2 is required."
  },
  {
    "objectID": "analysis/result.html",
    "href": "analysis/result.html",
    "title": "Conclusion",
    "section": "",
    "text": "We can observe that the best potential falls between Brooklyn and Queens. Far rockaway and Bronx are also promising. However, more specified conclusion can be drawn from clustering analysis. While Brooklyn tends to be more capable for development, Queens communities are more adaptive.\nFrom the process, we can compare between clustering and normal process of assessment. While using calibrated weight, we can get an overall adaptive capacity assessment using entropy-TOPSIS method, clustering analysis give us a better group of possible strategies to cope with each different type of community.\nFor a mid-sized census tract dataset, we need to better categorize the data to make a clear deduction from our findings, which will require a precise categorization approach to further develop our strategies. Clustering procedures are essential tools for multivariate statistical analysis, data mining, and unsupervised machine learning. Among clustering procedures (Anderberg, 2014) (Marzouk & Ghoniem, 2005), weighted k-means partitions minimize the sum of clusters’ second moments and create well-localized domains. K-means clustering is capable of partition units by spatial correlation. The K-means algorithm is suitable for the situation that the number of clusters has already been designated (Liu, et al., 2023).\nSo, in this scenario, TOPSIS is good for assessment job, while K-means algorithm is good for proposals. For communities classified as “at risk”, we would expect some extreme approaches to be used, including buyout. Local buyout coordinators and public hearing will be conducted. People living in these areas, primarily consisting of lower-income individuals, are predominantly made up of people residing in multi-family rental units. As rising floodwaters increasingly jeopardize their ability to live safely in their homes, these residents are likely to seek relocation assistance from the City, FEMA, or various charitable organizations. If there is a lack of accessible and affordable housing in areas with lower flood risks, these individuals might be compelled to relocate outside of New York City entirely. This potential displacement underscores the need for proactive measures to ensure the availability of safe, affordable housing options in less vulnerable areas. Careful selection of receiving communities and relocating can help these people get integrated into the new neighborhood and get better living conditions. Adapting, stable and future risk means by properly introducing flood mitigation measures, these communities can become receiving communities, relieving the pressure of the limited resources in existing receiving communities. Different development poential and social pressure determine how we choose destination communities when conductiong managed retreat projects."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Adaptive Capacity of New York City",
    "section": "",
    "text": "Following the devastating impacts of Hurricane Sandy in 2012 and Hurricane Ida in 2021, New York City has been recognized as facing a significantly underappreciated threat from storm-related destruction. These hurricanes have highlighted two distinct facets of climate change-related hazards. Hurricane Sandy exemplified the heightened future risk to coastal communities, a consequence of the synergistic effects of sea-level rise and storm surges. Conversely, Hurricane Ida underscored the susceptibility of the city’s aging and overburdened grey infrastructure to extreme rainfall events, particularly in older urban sectors.\n:::  :::\nSubstantial public funding has been directed to areas ravaged by recent disasters, leading to the establishment of initiatives such as Rebuild by Design. These initiatives facilitate dialogue between government entities and community leaders, strategizing neighborhood adaptation to evolving climatic patterns. Focus has predominantly been on coastal defense, exemplified by projects like the NY & NJ Harbor & Tributaries Focus Area Feasibility Study (US Army Corps of Engineers, 2022) and South Shore of Staten Island Coastal Storm Risk Management project (US Army Corps of Engineers, 2016). However, inland flooding, increasingly prevalent, continues to elude significant public attention. Insurance rates hasn’t been updated, especially in north Queens where casualties had been caused by Hurricane Ida and other flash flood events, and there has been appeals for FEMA to update (NYC Government, 2015).\nNew York City published Action Plan for the Remnants of Hurricane Ida (NYC DEP, 2023), and our research aligns with this initiative, focusing on risk assessment and community action plans that embrace a trifold strategy: flood mitigation, managed retreat, and densification. This strategy is underpinned by extensive research, incorporating historical flood data, infrastructure network analysis, and SRH-2D simulation modeling, and uses F-AHP – TOPSIS analysis approaches to generate risk assessment. The research phase also resembles the process of top-down approach. We also utilize the bottom-up approach, forming a hybrid methodology for synthesis as we finally categorize sample neighborhoods into three distinct groups: ‘At Risk’, potentially subject to buyout programs; ‘Intermediate’, need flood control systems for most extreme weather scenarios; and ‘Receiving’, envisioned as densified hubs for managed retreat, thereby bolstering local employment and business activities.\nOn this website, you will see how we have evaluated the Adaptive Capacity of communities in New York City.\n\n\n\n\n\n\nImportant\n\n\n\nThis piece of data mining is a part of a joint research and design project “Making Room for The Water (MRFTW)” by Rebuild by Design, ONE Architecture and University of Pennsylvania (https://rebuildbydesign.org/making-room-for-the-water/). This research phase is going to be concluded in a report based on my work and other people’s contributions. All direct contributions from other participants are filtered out so this website is individual work. Some data sources are obtained from events conducted by the research group."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Adaptive Capacity of New York City",
    "section": "",
    "text": "Following the devastating impacts of Hurricane Sandy in 2012 and Hurricane Ida in 2021, New York City has been recognized as facing a significantly underappreciated threat from storm-related destruction. These hurricanes have highlighted two distinct facets of climate change-related hazards. Hurricane Sandy exemplified the heightened future risk to coastal communities, a consequence of the synergistic effects of sea-level rise and storm surges. Conversely, Hurricane Ida underscored the susceptibility of the city’s aging and overburdened grey infrastructure to extreme rainfall events, particularly in older urban sectors.\n:::  :::\nSubstantial public funding has been directed to areas ravaged by recent disasters, leading to the establishment of initiatives such as Rebuild by Design. These initiatives facilitate dialogue between government entities and community leaders, strategizing neighborhood adaptation to evolving climatic patterns. Focus has predominantly been on coastal defense, exemplified by projects like the NY & NJ Harbor & Tributaries Focus Area Feasibility Study (US Army Corps of Engineers, 2022) and South Shore of Staten Island Coastal Storm Risk Management project (US Army Corps of Engineers, 2016). However, inland flooding, increasingly prevalent, continues to elude significant public attention. Insurance rates hasn’t been updated, especially in north Queens where casualties had been caused by Hurricane Ida and other flash flood events, and there has been appeals for FEMA to update (NYC Government, 2015).\nNew York City published Action Plan for the Remnants of Hurricane Ida (NYC DEP, 2023), and our research aligns with this initiative, focusing on risk assessment and community action plans that embrace a trifold strategy: flood mitigation, managed retreat, and densification. This strategy is underpinned by extensive research, incorporating historical flood data, infrastructure network analysis, and SRH-2D simulation modeling, and uses F-AHP – TOPSIS analysis approaches to generate risk assessment. The research phase also resembles the process of top-down approach. We also utilize the bottom-up approach, forming a hybrid methodology for synthesis as we finally categorize sample neighborhoods into three distinct groups: ‘At Risk’, potentially subject to buyout programs; ‘Intermediate’, need flood control systems for most extreme weather scenarios; and ‘Receiving’, envisioned as densified hubs for managed retreat, thereby bolstering local employment and business activities.\nOn this website, you will see how we have evaluated the Adaptive Capacity of communities in New York City.\n\n\n\n\n\n\nImportant\n\n\n\nThis piece of data mining is a part of a joint research and design project “Making Room for The Water (MRFTW)” by Rebuild by Design, ONE Architecture and University of Pennsylvania (https://rebuildbydesign.org/making-room-for-the-water/). This research phase is going to be concluded in a report based on my work and other people’s contributions. All direct contributions from other participants are filtered out so this website is individual work. Some data sources are obtained from events conducted by the research group."
  }
]